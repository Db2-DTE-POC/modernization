{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Db2 with Open Db2 Data Management Console Services\n",
    "The Db2 Data Management Console is more than a graphical user interface. It is a set of microservices that you can use to build custom applications to automate your use of Db2. \n",
    "\n",
    "This Jupyter Notebook contains examples of how to use the Open APIs and the composable interface that are available in the Db2 Data Management Console. Everything in the User Interface is also available through an open and fully documented RESTful Services API. The full set of APIs are documented as part of the Db2 Data Management Console user interface. In this hands-on-lab you can connect to the documentation directly through this link: [Db2 Data Management Console RESTful APIs](http://localhost:11080/dbapi/api/index_enterprise.html). \n",
    "\n",
    "You can also embed elements of the full user interface into an IFrame by constructing the appropriate URL. \n",
    "\n",
    "This hands on lab will be calling the Db2 Data Management Console as a service. However you can explore it through the user interface as well. Just click on the following link to try out the console that is already and setup in this lab: http://localhost:11080/console. If you have not already logged in you can use the following:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to find this sample online\n",
    "You can find a copy of this notebook at https://github.com/Db2-DTE-POC/db2dmc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will import a few helper classes\n",
    "We need to pull in a few standard Python libraries so that we can work with REST, JSON and a library called Pandas. Pandas lets us work with DataFrames, which are a very powerful way to work with tabular data in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class libraries \n",
    "import requests\n",
    "import ssl\n",
    "import json\n",
    "from pprint import pprint\n",
    "from requests import Response\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display, HTML\n",
    "from pandas.io.json import json_normalize\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Db2 Class\n",
    "Next we will create a Db2 helper class that will encapsulate the Rest API calls that we can use to directly access the Db2 Data Management Console service without having to use the user interface. \n",
    "\n",
    "To access the service we need to first authenticate with the service and create a reusable token that we can use for each call to the service. This ensures that we don't have to provide a userID and password each time we run a command. The token makes sure this is secure. \n",
    "\n",
    "Each request is constructed of several parts. First, the URL and the API identify how to connect to the service. Second the REST service request that identifies the request and the options. For example '/metrics/applications/connections/current/list'. And finally some complex requests also include a JSON payload. For example running SQL includes a JSON object that identifies the script, statement delimiters, the maximum number of rows in the results set as well as what do if a statement fails.\n",
    "\n",
    "The full set of APIs are documents as part of the Db2 Data Management Console user interface. In this hands on lab you can connect to that directly through this link: [Db2 Data Management Console RESTful APIs](http://localhost:11080/dbapi/api/index_enterprise.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Db2 Class library\n",
    "# Used to construct and reuse an Autentication Key\n",
    "# Used to construct RESTAPI URLs and JSON payloads\n",
    "class Db2():\n",
    "    \n",
    "    def __init__(self, url, verify = False, proxies=None, ):\n",
    "        self.url = url\n",
    "        self.proxies = proxies\n",
    "        self.verify = verify\n",
    "\n",
    "    def authenticate(self, userid, password, profile=\"\"):\n",
    "        credentials = {'userid':userid, 'password':password}\n",
    "        r = requests.post(self.url+'/auth/tokens', verify=self.verify, json=credentials, proxies=self.proxies)\n",
    "        if (r.status_code == 200):\n",
    "            bearerToken = r.json()['token']\n",
    "            if profile == \"\":\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken}\n",
    "            else:\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken, 'X-DB-Profile': profile}\n",
    "        else:\n",
    "            print ('Unable to authenticate, no bearer token obtained')\n",
    "        \n",
    "    def printResponse(self, r, code):\n",
    "        if (r.status_code == code):\n",
    "            pprint(r.json())\n",
    "        else:\n",
    "            print (r.status_code)\n",
    "            print (r.content)\n",
    "    \n",
    "    def getRequest(self, api, json=None):\n",
    "        return requests.get(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json)\n",
    "\n",
    "    def postRequest(self, api, json=None):\n",
    "        return requests.post(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json) \n",
    "        \n",
    "    def getStatusCode(self, response):\n",
    "        return (response.status_code)\n",
    "\n",
    "    def getJSON(self, response):\n",
    "        return (response.json())\n",
    "    \n",
    "    def getSchemas(self):\n",
    "        return self.getRequest('/schemas')\n",
    "    \n",
    "    def runSQL(self, script, limit=10, separator=';', stopOnError=False):\n",
    "        sqlJob = {'commands': script, 'limit':limit, 'separator':separator, 'stop_on_error':str(stopOnError)}\n",
    "        return self.postRequest('/sql_jobs',sqlJob)\n",
    "        \n",
    "    def getSQLJobResult(self, jobid):\n",
    "        return self.getRequest('/sql_jobs/'+jobid)\n",
    "    \n",
    "    def getCurrentApplicationsConnections(self, includeSystem='true'):\n",
    "        return self.getRequest('/metrics/applications/connections/current/list?&include_sys='+str(includeSystem))\n",
    "    \n",
    "    def getInflightCount(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/statements/inflight_executions/current/list?start='+str(startTime)+'&end='+str(endTime));\n",
    "       \n",
    "    def getInflightCurrentList(self, includeSystem='true'):\n",
    "        return self.getRequest('/metrics/statements/inflight_executions/current/list?'+'&include_sys='+str(includeSystem));\n",
    "    \n",
    "    def getIndividualStatementExecution(self, startTime, endTime, limit=100, includeSystem='false'):\n",
    "        return self.getRequest('/metrics/statements/evmon_activity?start='+str(startTime)+'&end='+str(endTime)+'&include_sys='+str(includeSystem)+'&offset=0&limit='+str(limit))\n",
    "\n",
    "    def getFiles(self, path):\n",
    "        return self.getRequest('/home'+path)\n",
    "    \n",
    "    def getUsers(self):\n",
    "        return self.getRequest('/users')\n",
    "    \n",
    "    def getTablesMetrics(self, startTime, endTime, includeSystem='false'):\n",
    "        return self.getRequest('/metrics/tables?start='+str(startTime)+'&end='+str(endTime)+'&include_sys='+str(includeSystem));\n",
    "\n",
    "    def getAverageResponseTime(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/average_response_time?start='+str(startTime)+'&end='+str(endTime));    \n",
    "    \n",
    "    def getUnitsOfWork(self, startTime, endTime):\n",
    "        return self.getRequest('/applications/uow?start='+str(startTime)+'&end='+str(endTime));    \n",
    "    \n",
    "    def getSchemaSize(self, startTime, endTime, tabSchema):\n",
    "        return self.getRequest('/metrics/storage/schemas/'+tabSchema+'/timeseries?start='+str(startTime)+'&end='+str(endTime));\n",
    "  \n",
    "    def getSearchViewList(self, searchtext, show_systems=\"false\"):\n",
    "        return self.getRequest('/admin/schemas/obj_type/view?search_name='+searchtext+'&show_systems='+str(show_systems)+'&rows_return=200');\n",
    "    \n",
    "    def getSearchTableList(self, searchtext):\n",
    "        return self.getRequest('/admin/schemas/obj_type/table?search_name='+searchtext+'&show_systems=true&rows_return=100');\n",
    "              \n",
    "    def getRowsRead(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/rows_read?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getResponseTime(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/response_time?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getStatementsCount(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/statements_count?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getPackageCacheStatement(self, startTime, endTime, show_systems='true'):\n",
    "        return self.getRequest('/metrics/statements/package_cache?start='+str(startTime)+'&end='+str(endTime)+'&include_sys='+str(show_systems))\n",
    "    \n",
    "    def postSearchObjects(self, obj_type, search_text, rows_return=100, show_systems='false', is_ascend='true'):     \n",
    "        json = {\"search_name\":search_text,\"rows_return\":rows_return,\"show_systems\":show_systems,\"obj_type\":obj_type,\"filters_match\":\"ALL\",\"filters\":[]}       \n",
    "        return self.postRequest('/admin/'+str(obj_type)+'s',json);\n",
    "                \n",
    "    def putFile(self, filename, path):\n",
    "        with open(filename, 'rb') as f:\n",
    "            r = requests.post(self.url+'/home_content/path', files={filename: f}, verify = self.verify, headers=self.headers, proxies = self.proxies)\n",
    "            \n",
    "    def getTablesInSchema(self, schema):\n",
    "        return self.getRequest('/schemas/'+str(schema)+'/tables');\n",
    "    \n",
    "    def getTableStorageBySchema(self):\n",
    "        return self.getRequest('/metrics/storage/schemas?end=0&include_sys=true&limit=1000&offset=0&start=0')\n",
    "    \n",
    "    def getCurrentPackageCacheList(self, show_systems=\"false\"):\n",
    "        return self.getRequest('/metrics/statements/package_cache/current/list?include_sys='+str(show_systems))\n",
    "    \n",
    "    def getProfile(self,profile):\n",
    "        return self.getRequest('/dbprofiles/'+profile)    \n",
    "    \n",
    "    def getMonitorStatus(self):\n",
    "        return self.getRequest('/monitor')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Classes\n",
    "Db2 returns time series data in Unix epoch time. The first function below converts between epoch and human readable time series format. The second function simply converts values from KB to GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data frame set calculation functions\n",
    "def epochtotimeseries(epoch):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(epoch/1000))\n",
    "def KBtoGB(kb):\n",
    "    return kb/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Calculations\n",
    "Since Db2 stores time series data as epoch time we need to do some simple calculations to determine current time as well as the duration of a week or a day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup time series calculation values\n",
    "import time\n",
    "from datetime import date\n",
    "endTime = int(time.time())*1000\n",
    "startTime = endTime-(600*1000)\n",
    "oneWeek = 604800000\n",
    "oneDay = oneWeek / 7\n",
    "oneHour = oneDay / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a Connection to the Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Connections\n",
    "To connect to the Db2 Data Management Console service you need to provide the URL, the service name (v4) and profile the console user name and password as well as the name of the connection profile used in the console to connect to the database you want to work with. For this lab we are assuming that the following values are used for the connection:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "* Connection: sample\n",
    "\n",
    "**Note:** If the Db2 Data Management Console has not completed initialization, the connection below will fail. Wait for a few moments and then try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'SAMPLE'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the connection\n",
    "To confirm that your connection is working you can check your console connection to get the details of the specific database connection you are working with. Since your console user id and password may be limited as to which databases they can access you need to provide the connection profile name to drill down on any detailed information for the database.\n",
    "Take a look at the JSON that is returned by the call in the cell below. You can see the name of the connection profile, the database name, the database instance the database belongs to, the version, release and edition of Db2 as well as the operating system it is running on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Monitoring Profile\n",
    "r = databaseAPI.getProfile(profile)\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the status of the moitoring service. This call take a bit longer since it is running a quick diagnostic check on the Db2 Data Management Console monitoring service. You should see that the both the database and authentication services are online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Monitor Status\n",
    "r = databaseAPI.getMonitorStatus()\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Available Schemas in the Database\n",
    "You can call the Db2 Data Management Console micro service to provide an active console component that you can include in an IFrame directly into your notebook. The first time you access this you will have to log in just like any other time you use the console for the first time. If you want to see all the schemas, including the catalog schemas, select the \"Show system schemas\" toggle at the right side of the panel. \n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "\n",
    "**Note:** You may need to logon to the console for the frame to be displayed.\n",
    "\n",
    "When the interface appears:\n",
    "\n",
    "Click on **Show system schemas** at the right side of the screen. This displays all the schemas in the Db2 catalog as well as user schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = database+'/console/?mode=compact#explore/schema'+profileURL\n",
    "print(URL)\n",
    "IFrame(URL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the same list through the REST service call. In this example the service call text was defined in the Db2 class at the start of the notebook. By default it includes both user and catalog schemas. \n",
    "\n",
    "If the call is successful it will return a 200 status code. The API call returns a JSON structure that we turn into a DataFrame using the normalize function. You can then list the columns of data available in the Data Frame and display the first 10 rows in the data frame. \n",
    "\n",
    "Many of the examples below list the columns available in the dataframe to make it easier for you to adapt the examples to your own needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = databaseAPI.getSchemas()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Key Performance Metrics\n",
    "You can access key high level performance metrics by directly including the monitoring summary page in an IFrame or calling the available API. To see the time series history of the number of rows read in your system over the last day, run the statement below. Then scroll to the right side and find the Database Throughput Widget. Then select Rows Read and Last 24 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = database+'/console/?mode=compact#monitor/summary'+profileURL\n",
    "print(URL)\n",
    "IFrame(URL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the same data directly through an API you can use the getRowsRead function as defined in the Db2 class at the start of the notebook. To extract the timeseries data from the JSON returned from the API call you need to access the 'timeseries' part of the full JSON data set. \n",
    "\n",
    "The example below retrieves the last hour of data, converts it from JSON to a DataFrame and then displays and graphs the data. Notice that the timeseries data is returned as EPOC data. That is the number of seconds since January 1st 1970. The epochtotimeseries routine we created earlier in the lab converts that to human readable timeseries data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the number of rows read over the last day\n",
    "# List the last 10 data points\n",
    "# Graph the history\n",
    "\n",
    "endTime = int(time.time())*1000\n",
    "oneHour = 3600000\n",
    "# Return the rows read rate over the last hour\n",
    "r = databaseAPI.getRowsRead((endTime-oneHour), endTime)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0:\n",
    "        df = pd.DataFrame(json_normalize(json['timeseries'])) #extract just the timeseries data\n",
    "        print('Available Columns')\n",
    "        print(', '.join(list(df)))\n",
    "        # Convert from EPOCH to timeseries data\n",
    "        df['timestamp'] = df['timestamp'].apply(epochtotimeseries)\n",
    "        display(df[['timestamp','rows_read_per_min']].tail(20))\n",
    "        df.plot.line(x='timestamp',y='rows_read_per_min') \n",
    "        plt.show()\n",
    "    else: \n",
    "        print('No data returned')\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Usage\n",
    "You can access the storage report page directly by calling it into an IFrame or you can access the data from an API. In the report below you can select the timeframe for storage usage, group by table or schema, select the object you want to analyze and then select View Details from the Actions column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = database+'/console/?mode=compact#monitor/storage'+profileURL\n",
    "print(URL)\n",
    "IFrame(URL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list storage by schema. The following example retrieves the current level of storage usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List storage used by schema\n",
    "# Display the top ten schemas\n",
    "r = databaseAPI.getTableStorageBySchema()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)        \n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        print(', '.join(list(df)))\n",
    "        df['space_mb'] = df['data_physical_size_kb'].apply(lambda x: x / 1024)\n",
    "        df = df.sort_values(by='data_physical_size_kb', ascending=False)    \n",
    "        display(df[['tabschema','space_mb']].head(10))\n",
    "    else: \n",
    "        print('No data returned') \n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Management\n",
    "You can explore the objects in your database through the search objects API. This API requires an JSON payload to define the search criteria which can be complex. In this example we are looking for Views with \"table\" in their name. It will search through both user and catalog views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for tables across all schemas that match simple search critera \n",
    "# Display the first 100\n",
    "# Switch between searching tables or views\n",
    "object = 'view'\n",
    "# object = 'table'\n",
    "r = databaseAPI.postSearchObjects(object,\"TABLE\",10,'true','false')\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json))\n",
    "    print('Columns:')\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[[object+'_name']].head(100))\n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example returns all the tables in a single schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tables in the SYSIBM schema and display the first 10\n",
    "schema = 'SYSIBM'\n",
    "r = databaseAPI.getTablesInSchema(schema)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['schema','name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement Monitoring\n",
    "You can also review the currently running or \"In-Flight\" statements in the database. Both a user interface as well as a REST call are available. \n",
    "When the interface below appears, select the SYS icon at the right side of the page. This will display both the user statements as well as those statements initiated by the Db2 Data Management Console to monitor your database. You can also choose a longer timeframe to see a history of the statements that were running when the console polled the database. This happens every few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = database+'/console/?mode=compact#monitor/inflight_executions'+profileURL\n",
    "print(URL)\n",
    "IFrame(URL, width=1400, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the same information using a REST call. The example below only looks at what is running right now and it includes all statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the current statements running now\n",
    "# Display the top 10 by execution time\n",
    "r = databaseAPI.getInflightCurrentList()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0:\n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        print('Columns')\n",
    "        print(', '.join(list(df)))\n",
    "        df = df.sort_values(by='exec_time_ms', ascending=False)\n",
    "        display(df[['application_name','stmt_text','exec_time_ms','estimated_runtime_ms']].head(10))\n",
    "    else:\n",
    "        print('No data returned')\n",
    "else:\n",
    "    code = databaseAPI.getStatusCode(r)\n",
    "    databaseAPI.printResponse(r, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also retrieve the current package cache list. The example below returns a list of all the statements currently in the package cache. There are more examples of using this with active workloads in the [Analysing SQL Workloads](http://localhost:8888/notebooks/Db2_Data_Management_Console_SQL.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the current package cache list \n",
    "# sorted by the statement execution time\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "r = databaseAPI.getCurrentPackageCacheList(\"false\")\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0:  \n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        df = df.sort_values(by='stmt_exec_time_ms', ascending=False)\n",
    "        display(df[['stmt_text','stmt_exec_time_ms','stmtid']])\n",
    "    else: \n",
    "        print('No data returned')  \n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection Monitoring\n",
    "This next example demonstrates how to see what applications are connected to your database. Try clicking on the SYS icon at the right to show or hide the applications associated with the Db2 Data Management Console monitoring service. You can also choose different timeframes in this view to see the history of database connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = database+'/console/?mode=compact#monitor/connections'+profileURL\n",
    "print(URL)\n",
    "IFrame(URL, width=1400, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next example retrieves the 10 most recently started database connections. You should be able to see the python application in the list, which is coming from this notebook. UC_MYMON is the Db2 Data Management Console monitoring service. Take a look at the columns returned in the JSON structure. You may want to try re-running this cell with different columns is the display command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 10 most recently started Database Connections\n",
    "r = databaseAPI.getCurrentApplicationsConnections()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        print(', '.join(list(df)))\n",
    "        df = df.sort_values(by='connection_start_time', ascending=False)\n",
    "        df['connection_start_time'] = df['connection_start_time'].apply(epochtotimeseries)\n",
    "        # Try different columns from the list below and explore the additional data available. \n",
    "        display(df[['application_name','application_handle','connection_start_time']].head(10))\n",
    "    else: \n",
    "        print('No data returned')  \n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Your History Database\n",
    "In this hands on lab, there are two databases in use. So far you have been connected to the SAMPLE database. The other database, HISTORY stores all the monitoring data collected by the Db2 Data Management Console monitoring service.\n",
    "\n",
    "If we connect to the HISTORY database we can check the history of how much data is being collected over time by the monitoring service.\n",
    "\n",
    "In this next cell we will switch from the SAMPLE to the HISTORY database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'HISTORY'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell retrieves the storage history for the Historical Data Repostory stored in IBMCONSOLE schema. If this doesn't run against the repository database you will get a zero result set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the last 10 data points\n",
    "# Graph the history of the storage usage\n",
    "tabSchema = 'IBMCONSOLE'\n",
    "OneWeekStartTime = endTime - oneWeek\n",
    "r = databaseAPI.getSchemaSize(0, endTime, tabSchema)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['timeseries']))\n",
    "        print('Columns')\n",
    "        print(', '.join(list(df)))\n",
    "        df['total_physical_size_gb'] = df['total_physical_size_kb'].apply(KBtoGB)\n",
    "        df['timestamp'] = df['timestamp'].apply(epochtotimeseries)\n",
    "        display(df[['timestamp','total_physical_size_gb']].tail(10))\n",
    "        df.plot(x='timestamp',y='total_physical_size_gb')\n",
    "    else: \n",
    "        print('No data returned') \n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Try the [Analysing SQL Workloads](http://localhost:8888/notebooks/Db2_Data_Management_Console_SQL.ipynb). It contains extensive examples on how to run workloads that contain multiple SQL Statements across multiple databases and then measure their performance. \n",
    "\n",
    "Also try building some of your own reports based on the examples in this hands on lab. There are additional functions included in the Db2 class that we haven't explored yet in this lab. You can also include the Db2 class into your own notebook by including the [dmc_setup notebook](http://localhost:8888/notebooks/dmc_setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019, Peter Kohlmann [kohlmann@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
