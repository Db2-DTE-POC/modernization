{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing SQL Workloads\n",
    "\n",
    "This Jupyter Notebook contains examples of how to use the open APIs of the Db2 Data Management Console to run SQL scripts and use Visual Explain in to analyze SQL. You will start with single SQL statements and work up to running multiple statements against multiple databases to simulate a production workload. By measuring performance over several runs you can identify the slowest statement and the slowest database. Finally you can experiment with different indexes to see if you can improve the performance of the workload. \n",
    "\n",
    "The Db2 Data Management Console is more than a graphical user interface. It is a set of microservices that you can use to build custom applications to automate your use of Db2.\n",
    "\n",
    "This Jupyter Notebook contains examples of how to use the Open APIs and the composable interface that are available in the Db2 Data Management Console. Everything in the User Interface is also available through an open and fully documented RESTful Services API. The full set of APIs are documented as part of the Db2 Data Management Console user interface. In this hands on lab you can connect to the documentation directly through this link: [Db2 Data Management Console RESTful APIs](http://localhost:11080/dbapi/api/index_enterprise.html). \n",
    "\n",
    "You can also embed elements of the full user interface into an IFrame by constructing the appropriate URL.\n",
    "\n",
    "This hands on lab will be calling the Db2 Data Management Console as a service. However you can explore it through the user interface as well. Just click on the following link to try out the console that is already and setup in this lab: http://localhost:11080/console. If you have not already logged in you can use the following:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to find this sample online\n",
    "You can find a copy of this notebook at https://github.com/Db2-DTE-POC/db2dmc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Helper Classes\n",
    "For more information on these classes, see the lab: [Automate Db2 with Open Console Services](http://localhost:8888/notebooks/Db2_Data_Management_Console_Overview.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./dmc_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Db2 Data Management Console Connection\n",
    "To connect to the Db2 Data Management Console service you need to provide the URL, the service name (v4) and profile the console user name and password as well as the name of the connection profile used in the console to connect to the database you want to work with. For this lab we are assuming that the following values are used for the connection:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "* Connection: sample\n",
    "\n",
    "**Note:** If the Db2 Data Management Console has not completed initialization, the connection below will fail. Wait for a few moments and then try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'Sample'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "\n",
    "if databaseAPI.authenticate(user, password, profile) :\n",
    "    print(\"Token Created\")\n",
    "else : \n",
    "    print(\"Token Creation Failed\")\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the connection\n",
    "To confirm that your connection is working you can check the status of the moitoring service. You can also check your console connection to get the details of the specific database connection you are working with. Since your console user id and password may be limited as to which databases they can access you need to provide the connection profile name to drill down on any detailed information for the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Monitoring Profile\n",
    "r = databaseAPI.getProfile(profile)\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Db2 Console through custom URLs\n",
    "This lab provides direct links to specific pages in the Db2 Console to make it easy to navigate during the lab. Since you can use this lab from a browser running in the virtual desktop or from your own browser on your own desktop, we just need to save the location of the console you are using. \n",
    "\n",
    "By default it is setup to use links that will work from the virtual machine desktop. To run from your own browser on your own desktop, enter the port location of the Db2 Console provided in your welcome note and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalConsole = \"http://services-uscentral.skytap.com:18638\"\n",
    "database = externalConsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Custom URL\n",
    "Run the cell below.\n",
    "\n",
    "It will generate a link to the console that works for your selected environment. Notice that it brings up the whole console including the full navigation menu.\n",
    "\n",
    "Right click on the link and select Open Link in New Tab or Open Link in New Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database+'/console/?mode=compact#explore/table?profile=Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Db2 class to run SQL\n",
    "You can use the console API to run single SQL statement or sets of statements in a single call. A step by step explanation of running SQL through the Db2 Data Management Console SQL service is available in the [Db2 SQL with RESTful Services](http://localhost:8888/notebooks/Db2_RESTful_APIS.ipynb) Jupyter notebook. These examples use the Db2 class defined in [dmc_setup.ipynb](http://localhost:8888/notebooks/dmc_setup.ipynb). The Db2 class takes care of creating a reusable authentication key from your login information. It includes two routines **runSQL** and **getSQLJobResult** that make submitting SQL scripts easy. **runSQL** uses the console service to run one or more statements in the background, saving the result. **getSQLJobResult** lets you access the results of each statement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example we will run a single statement. The first step defines a single statement, runs the SQL and retrieves a unique id to identify the SQL running in the background. Using that id you can check the job results to see if it is still running or complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run SQL Statement and Retrieve the identifier used to track the run\n",
    "\n",
    "# Define the SQL to Run\n",
    "sqlText = 'select TABSCHEMA, TABNAME from syscat.tables'\n",
    "\n",
    "# Run SQL throught the Console SQL Editor REST Service\n",
    "r = databaseAPI.runSQL(sqlText)\n",
    "\n",
    "# Retrieve the run identifier from the SQL Editor Service\n",
    "runID = databaseAPI.getJSON(r)['id'] \n",
    "\n",
    "# Using the saved runID retrieve a JSON description of the run\n",
    "json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID)) \n",
    "\n",
    "# Extract the status of the run from the JSON return and print the runID as well as its status\n",
    "if json['results'] == [] :\n",
    "    print(runID+\" \"+json['status']) \n",
    "else :\n",
    "    print('JSON Results')\n",
    "    print(json['results']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we check that the statement has finished running. Then we check for three possible conditions. First, if there was an error in the SQL Statement. If so, we print the error message. Second, did the statement run successfully and is there a result set. If so, we print out the results as a table. And third, there are no errors but also no results are returned. Try running different SQL Statements to see the different results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS STEP IF THERE WERE NO RESULTS FROM THE PREVIOUS STEP\n",
    "# Even if the status is running. You need to extract and process the results before you get more results.\n",
    "# Once you have retrieved the results you cannot run the same call a second time successfully.\n",
    "# The JSON structure is only available on the first call.\n",
    "json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us unpack the JSON that returned in the cell above. The code below checks that the statement completed and checks for errors. If there are no errors and rows were returned in a result set, then the rows are extracted to a dataframe and displayed. Dataframes are a very powerful part of the Python Panda's library. They let us easily manupulate data sets that come back from Db2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if json['results'] != []:\n",
    "        results = json['results'][0]\n",
    "        if 'error' in results : \n",
    "            print(results['error'])\n",
    "        elif 'rows' in results :\n",
    "            df = pd.DataFrame(results['rows'],columns=results['columns'])\n",
    "            print(df)\n",
    "        else :\n",
    "            print('No errors. No results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not want to have to continously check to see if a statement is complete. So let us use a simple loop to do the checking for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SQL Statement and Retrieve the identifier used to track the run\n",
    "sqlText = 'select TABSCHEMA, TABNAME from syscat.tables'\n",
    "runID = databaseAPI.getJSON(databaseAPI.runSQL(sqlText))['id'] \n",
    "print('Run Identifier: '+str(runID))\n",
    "\n",
    "# Check to see if the statement finished running\n",
    "json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "\n",
    "# If the statement still has not finished wait in one second intervals\n",
    "# we check for results because depending on timing it is possible to retrieve results without the status being complete.\n",
    "# Once we retrieve the results there are removed from the service. \n",
    "while json['results'] == [] :\n",
    "    json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "    time.sleep(1) \n",
    "    \n",
    "# Assuming we only have one statement, unpack the results    \n",
    "results = json['results'][0]\n",
    "if 'error' in results : \n",
    "    print(results['error'])\n",
    "elif 'rows' in results :\n",
    "    df = pd.DataFrame(results['rows'],columns=results['columns'])\n",
    "    print(df)\n",
    "else :\n",
    "    print('No errors. No results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Scripts Used in the Lab\n",
    "We are going to define a few scripts that we will use during this lab. The first two will define tables that are used during the rest of the lab. The third defines a workload we will reuse. Notice that these scripts contain multiple SQL statements. We are going to have to update our code to handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlScriptCreateEmployee = \\\n",
    "'''\n",
    "CREATE TABLE EMPLOYEES (ENO INTEGER, DEPTNO INTEGER, LASTNAME VARCHAR(30),\n",
    "    HIREDATA DATE, SALARY INTEGER);\n",
    "\n",
    "INSERT INTO EMPLOYEES\n",
    "-- generate 500000 records\n",
    "    WITH DT(ENO) AS (VALUES(1) UNION ALL SELECT ENO+1 FROM DT WHERE ENO < 500000)\n",
    "\n",
    "-- Now, use the generated records in DT to create other columns\n",
    "-- of the employee record.\n",
    "    SELECT ENO,\n",
    "    RAND() * 500,\n",
    "    TRANSLATE(CHAR(INTEGER(RAND()+500000)),\n",
    "    CASE MOD(ENO,5) WHEN 0 THEN 'aeiou' || 'bcdfg'\n",
    "        WHEN 1 THEN 'aeiou' || 'hjklm'\n",
    "        WHEN 2 THEN 'aeiou' || 'npqrs'\n",
    "        WHEN 3 THEN 'fredr' || 'annab'\n",
    "        ELSE 'aeiou' || 'twxyz' END,\n",
    "        '1234567890') AS LASTNAME,\n",
    "   CURRENT DATE - (RAND()*10957) DAYS AS HIREDATE,\n",
    "   INTEGER(1000*RAND()*200) AS SALARY\n",
    "   FROM DT;\n",
    "\n",
    "SELECT COUNT FROM EMPLOYEES;\n",
    "\n",
    "SELECT * FROM EMPLOYEES ORDER BY ENO;\n",
    "'''\n",
    "print(\"Defined Create Employee Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlScriptCreateDepartment = \\\n",
    "'''\n",
    "CREATE TABLE DEPARTMENTS (DEPTNO INTEGER, DEPTNAME VARCHAR(30), REVENUE BIGINT);\n",
    "\n",
    "INSERT INTO DEPARTMENTS\n",
    "-- generate 500 department records\n",
    "WITH DT(DEPTNO) AS (VALUES(1) UNION ALL SELECT DEPTNO+1 FROM DT WHERE DEPTNO < 500 )\n",
    "\n",
    "    SELECT DEPTNO,\n",
    "        TRANSLATE(CHAR(INTEGER(RAND()+100000)),\n",
    "            CASE MOD(DEPTNO,5) WHEN 0 THEN 'aeiou' || 'bcdfg'\n",
    "                WHEN 1 THEN 'aeiou' || 'hjklm'\n",
    "                WHEN 2 THEN 'aeiou' || 'npqrs'\n",
    "                WHEN 3 THEN 'fredr' || 'annab'\n",
    "                ELSE 'aeiou' || 'twxyz' END,\n",
    "                '1234567890') AS DEPTNAME,\n",
    "        BIGINT(100000*RAND()*50000) AS REVENUE\n",
    "        FROM DT;\n",
    "\n",
    "SELECT COUNT FROM DEPARTMENTS;\n",
    "\n",
    "SELECT * FROM DEPARTMENTS;\n",
    "'''\n",
    "print(\"Defined Create Department Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlScriptWorkload1 = \\\n",
    "'''\n",
    "WITH SALARYBY (DEPTNO, TOTAL) AS\n",
    "    (SELECT DEPT.DEPTNO DNO, SUM(BIGINT(EMP.SALARY)) TOTAL_SALARY\n",
    "        FROM EMPLOYEES EMP, DEPARTMENTS DEPT\n",
    "        WHERE DEPT.DEPTNO = EMP.DEPTNO AND EMP.SALARY > 190000\n",
    "        GROUP BY DEPT.DEPTNO\n",
    "        ORDER BY DNO)\n",
    "SELECT DEPT.DEPTNAME NAME, SALARYBY.TOTAL COST, DEPT.REVENUE, DEPT.REVENUE-SALARYBY.TOTAL PROFIT\n",
    "FROM SALARYBY, DEPARTMENTS DEPT\n",
    "WHERE DEPT.DEPTNO = SALARYBY.DEPTNO\n",
    "AND REVENUE > TOTAL\n",
    "ORDER BY PROFIT\n",
    "'''\n",
    "print(\"Defined Workload 1 Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlScriptWorkload2 = \\\n",
    "'''\n",
    "SELECT DEPT.DEPTNO DNO, SUM(FLOAT(EMP.SALARY)) TOTAL_SALARY\n",
    "  FROM EMPLOYEES EMP, DEPARTMENTS DEPT \n",
    "  WHERE DEPT.DEPTNO = EMP.DEPTNO \n",
    "      AND EMP.SALARY < 50000\n",
    "      AND YEAR(EMP.HIREDATA) > 2010\n",
    "  GROUP BY DEPT.DEPTNO\n",
    "  ORDER BY DNO;\n",
    "\n",
    "SELECT DEPT.DEPTNO DNO, SUM(FLOAT(EMP.SALARY)) TOTAL_SALARY\n",
    "  FROM EMPLOYEES EMP, DEPARTMENTS DEPT \n",
    "  WHERE DEPT.DEPTNO = EMP.DEPTNO \n",
    "      AND EMP.SALARY < 190000\n",
    "      AND YEAR(EMP.HIREDATA) > 2010\n",
    "  GROUP BY DEPT.DEPTNO\n",
    "  ORDER BY DNO;\n",
    "\n",
    "SELECT DEPT.DEPTNO, DEPT.REVENUE\n",
    "  FROM DEPARTMENTS DEPT WHERE DEPT.REVENUE > 450000000;\n",
    "'''\n",
    "print(\"Defined Workload 2 Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addMoreRows = \\\n",
    "'''\n",
    "INSERT INTO EMPLOYEES\n",
    "-- generate 500000 records\n",
    "    WITH DT(ENO) AS (VALUES(1) UNION ALL SELECT ENO+1 FROM DT WHERE ENO < 500000)\n",
    "\n",
    "-- Now, use the generated records in DT to create other columns\n",
    "-- of the employee record.\n",
    "    SELECT ENO,\n",
    "    RAND() * 500,\n",
    "    TRANSLATE(CHAR(INTEGER(RAND()+500000)),\n",
    "    CASE MOD(ENO,5) WHEN 0 THEN 'aeiou' || 'bcdfg'\n",
    "        WHEN 1 THEN 'aeiou' || 'hjklm'\n",
    "        WHEN 2 THEN 'aeiou' || 'npqrs'\n",
    "        WHEN 3 THEN 'fredr' || 'annab'\n",
    "        ELSE 'aeiou' || 'twxyz' END,\n",
    "        '1234567890') AS LASTNAME,\n",
    "   CURRENT DATE - (RAND()*10957) DAYS AS HIREDATE,\n",
    "   INTEGER(1000*RAND()*200) AS SALARY\n",
    "   FROM DT;\n",
    "'''\n",
    "print(\"Defined Add More Rows Script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Multiple SQL Statements in a Single Script\n",
    "In the following example we run multiple statements in a single API call. When the statement is started we get a run handle we can use to access the results of the SQL execution. Running the script works the same as running a single statement. However, retrieving results is more complex. Each time you check for results you may get the results of one or more statements. Like before, you can only retrieve the results for each statement once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SQL Statement and Retrieve the identifier used to track the run\n",
    "\n",
    "sqlText = sqlScriptCreateEmployee\n",
    "runID = databaseAPI.getJSON(databaseAPI.runSQL(sqlText))['id'] \n",
    "print(runID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a loop to check for results \n",
    "# Each time we retrieve new results they are added to the fulljson result set\n",
    "\n",
    "json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "print(\"Check for Results\")\n",
    "fulljson = json\n",
    "\n",
    "while json['results'] != [] or (json['status'] != \"completed\" and json['status'] != \"failed\") :\n",
    "    json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "    print(\"Check for results\")\n",
    "    for results in json['results'] :\n",
    "        fulljson['results'].append(results)\n",
    "    time.sleep(1) \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to unpack the entire JSON result set\n",
    "# and display if each statement ran successfully and how long it took\n",
    "# we also extract how many rows were affected for insert statements\n",
    "\n",
    "for results in fulljson['results']:\n",
    "    print('Statement: '+str(results['index'])+': '+results['command'])\n",
    "    print('Runtime ms: '+str(results['runtime_seconds']*1000))\n",
    "    if 'error' in results : \n",
    "        print(results['error'])\n",
    "    elif 'rows' in results :\n",
    "        df = pd.DataFrame(results['rows'],columns=results['columns'])\n",
    "        print(df)\n",
    "    else :\n",
    "        print('No errors. Row Affected: '+str(results['rows_affected']))\n",
    "    print()\n",
    "    print('* * * * * * * * * * * * * * *')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Routine to Run an SQL Script\n",
    "To make things easier we can create reusable routines that will included everything we have developed so far. By running the next two steps, you create two routines that you can call by passing parameters to them. \n",
    "\n",
    "While we could create a single routine to run SQL and then display the results, we are creating two different routines so that we can display the results differently later in the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSQL(profile,user, password, sqlText):\n",
    "    \n",
    "    if databaseAPI.authenticate(user, password, profile) :\n",
    "\n",
    "        # Run the SQL Script and return the runID for later reference \n",
    "        runID = databaseAPI.getJSON(databaseAPI.runSQL(sqlText))['id'] \n",
    "\n",
    "        # See if there are any results yet for this job\n",
    "        json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "        \n",
    "        # If the REST call returns an error return the json with the error to the calling routine\n",
    "        if 'errors' in json :\n",
    "            return json\n",
    "        # Append the results from each statement in the script to the overall combined JSON result set\n",
    "        fulljson = json\n",
    "\n",
    "        while json['results'] != [] or (json['status'] != \"completed\" and json['status'] != \"failed\") :\n",
    "            json = databaseAPI.getJSON(databaseAPI.getSQLJobResult(runID))\n",
    "\n",
    "            # Get the results from each statement as they return and append the results to the full JSON \n",
    "            for results in json['results'] :\n",
    "                fulljson['results'].append(results)\n",
    "            # Wait 250 ms for more results\n",
    "            time.sleep(0.25) \n",
    "        return fulljson\n",
    "    else :\n",
    "        print('Could not authenticate')\n",
    "print('runSQL routine defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayResults(json):\n",
    "\n",
    "    for results in json['results']:\n",
    "        print('Statement: '+str(results['index'])+': '+results['command'])\n",
    "        print('Runtime ms: '+str(results['runtime_seconds']*1000))\n",
    "        if 'error' in results : \n",
    "            print(results['error'])\n",
    "        elif 'rows' in results :\n",
    "            df = pd.DataFrame(results['rows'],columns=results['columns'])\n",
    "            print(df)\n",
    "        else :\n",
    "            print('No errors. Row Affected: '+str(results['rows_affected']))\n",
    "        print()\n",
    "print('displayResults routine defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the new routine using the parameters to define the connection profile to use, the userid and password and the SQL Text. In this example we will drop the table we just created. Try running it a second time. You can see that it correctly returns an error message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = 'SAMPLE'\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "sqlText = 'DROP TABLE EMPLOYEES'\n",
    "displayResults(runSQL(profile, user, password, sqlText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Multiple Scripts across Multiple Databases\n",
    "Now we will use our new routines to create the Employees and the Department tables across two databases. In this lab we can use the SAMPLE and the HISTORY database. The example below loops through two databases and two scripts to create the required tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [sqlScriptCreateEmployee, sqlScriptCreateDepartment]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('* * * * * * * * * * * * * * * * * * * * * * * * * * *')\n",
    "    print('Running Scripts against profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating a script across multiple databases\n",
    "**Step 1:** If we insert too many rows in one step to the EMPLOYEES table we will exceed the capacity of the transaction log, as it is currently configured. So let's add 1 million more rows to the employee table in both HISTORY and SAMPLE by adding 500,000 2 times. Run the cell below.\n",
    "\n",
    "**Step 2:** To make things more interesting we will measure the difference in performance between the HISTORY and SAMPLE databases. We can make the job harder for one database by adding more rows just to one database. Delete the HISTORY database from the profile list in the cell below. Then change the number of profileReps from 2 to 4 and run the cell again. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileList = ['SAMPLE']\n",
    "scriptList = [addMoreRows]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "profileReps = 4\n",
    "\n",
    "for profile in profileList :\n",
    "    for x in range(0, profileReps):\n",
    "        print('Repetition number: '+str(x))\n",
    "        print('Running Scripts against profile: '+profile)\n",
    "        for script in scriptList :\n",
    "            json = runSQL(profile, user, password, script)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the number of rows in the employees table in the SAMPLE and the HISTORY database. There should be 3,500,000 rows in SAMPLE and 1,500,000 in HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = ['select count(*) from employees']\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('Running Scripts against profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running multiple scripts across multiple databases - Summarized Results\n",
    "Now that we have our tables created on both databases, we can run workloads and measure their performance. By repeatedly running the scripts across multiple databases in a single Db2 instance we can simulate a real database environemt. \n",
    "\n",
    "Instead of using the displayResults routine we are going to capture runtime metrics for each run of the SQL Query workloads so that we can analyze performance. The appendResults routine builds this dataframe with each pass.\n",
    "\n",
    "runScripts lets use define the database connection profiles we want to run against, the scripts to run, and now many times to repeat the runs for each profile and for each script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine builds up a Data Frame containing the run results as we run workloads across databases\n",
    "def appendResults(df, profile, json) :\n",
    "    \n",
    "    error = ''\n",
    "    rows = 0\n",
    "    if 'error' in json :\n",
    "        print('SQL Service Failed')\n",
    "    else :\n",
    "        for results in json['results']:\n",
    "            if 'error' in results : \n",
    "                error = results['error']\n",
    "            if 'rows_affected' in results : \n",
    "                rows = results['rows_affected']\n",
    "            df = df.append({'profile':profile,'index':results['index'], 'statement':results['command'], 'error':error, 'rows_affected': rows, 'runtime_ms':(results['runtime_seconds']*1000)}, ignore_index=True)\n",
    "        return df\n",
    "print('appendResults routine defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine runs multistatment scripts across multiple databases. \n",
    "# The scripts are run repeatedly for each profile (database)\n",
    "def runScripts(profileList, scriptList, user, password, profileReps, scriptReps) :\n",
    "\n",
    "    df = pd.DataFrame(columns=['profile', 'index', 'statement', 'error', 'rows_affected', 'runtime_ms'])\n",
    "    \n",
    "    for x in range(0, profileReps):\n",
    "        print(\"Running repetition: \"+str(x))\n",
    "        for profile in profileList :\n",
    "            print(\"  Running scripts against: \"+profile)\n",
    "            for y in range(0, scriptReps) :\n",
    "                print(\"    Running script repetition: \"+str(y))\n",
    "                for script in scriptList :\n",
    "                    json = runSQL(profile, user, password, script)\n",
    "                    while 'errors' in json:\n",
    "                        print('    * Trying again *')\n",
    "                        json = runSQL(profile, user, password, script)\n",
    "                    df = appendResults(df, profile, json)\n",
    "                        \n",
    "    return df\n",
    "print('runScripts routine defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the current package cache list \n",
    "# Show the first ten as sorted by the statement execution time\n",
    "def getCurrentPackageCacheListDF(profile) :\n",
    "    databaseAPI.authenticate(user, password, profile)\n",
    "    r = databaseAPI.getCurrentPackageCacheList(\"false\")\n",
    "    if (databaseAPI.getStatusCode(r)==200):\n",
    "        json = databaseAPI.getJSON(r)\n",
    "        if json['count'] > 0:  \n",
    "            df = pd.DataFrame(json_normalize(json['resources']))\n",
    "            df = df.sort_values(by='stmt_exec_time_ms', ascending=False)\n",
    "            return df\n",
    "        else: \n",
    "            print('No data returned') \n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loops through a list of databases as well as a list of scripts and run then repeatedly. You an set the number of times the scripts are run against each database and the number of times the runs against both databases is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [sqlScriptWorkload1, sqlScriptWorkload2]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "profileReps = 2\n",
    "scriptReps = 4\n",
    "\n",
    "df = runScripts(profileList, scriptList, user, password, profileReps, scriptReps)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the contents of the package cache from both databases. You can compare the package cache measurement to your actual runtimes. If you wait too long between your run and when you check the package cache your statements may have already been pushed out of the package cache. You can always try the test run in the cell above again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile in profileList:\n",
    "    print('Profile: '+profile)\n",
    "    packageCacheDF = getCurrentPackageCacheListDF(profile)\n",
    "    if packageCacheDF.empty == True :\n",
    "        print(\"No statements in the package cache\")\n",
    "    else :\n",
    "        display(packageCacheDF[['stmt_text','stmt_exec_time_ms','stmtid']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results\n",
    "Now we can use the results in the dataframe to look at the results statistically. First we can see the average runtime for each statement across the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean runtime in ms')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "stmtMean = df.groupby(['statement']).mean()\n",
    "print(stmtMean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the total runtime for each statement across databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total runtime in ms')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "stmtSum = df.groupby(['statement']).sum()\n",
    "print(stmtSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even graph the total run time for all the statements can compare database performance. Since there are more rows in the employees table in the SAMPLE database it takes longer for the queries to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean runtime in ms')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "profileSum = df.groupby(['profile']).sum()\n",
    "profileSum.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the Db2 Data Management Console directly to look at the package cache and the package cache history.\n",
    "\n",
    "Run the following cell and log in using **DB2INST1** as the userid and password. The cell calls the console as a micro-service and includes part of the live user interface into a IFrame directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database+'/console/?mode=compact#monitor/package_cache'+profileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the timeframe from **Latest** to **Last 1 hour** so you can see a history of package cache monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a Single Statement\n",
    "You can identify the slowest SQL statement and the slowest database to focus your attention. The next two cells will to that by scanning through our previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slowest SQL Statement')\n",
    "slowestSQL = stmtSum['runtime_ms'].idxmax()\n",
    "print(slowestSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slowest Database')\n",
    "slowestProfile = profileSum['runtime_ms'].idxmax()\n",
    "print(slowestProfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very powerful tool that you can include directly into your notebook is Visual Explain. Just like being able to explore the package cache history you can call the micro-service that provides a live intertive interface. In this example we will take the slowest statment on the slowest database and explain the statement. \n",
    "\n",
    "**3.1.1 Note:** Unfortunately there was a regression in ability to call this function directly through a URL. It is supported in 3.1 and will be addressed in 3.1.2. If you are currently using 3.1.1 please copy the SQL statement above, copy it into the Db2 Console SQL Editor and select the Visual Explain tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually explain the access plan for an SQL Statement\n",
    "profileURL = \"?profile=\"+slowestProfile\n",
    "stmt = slowestSQL.replace('\\n', ' ').replace('\\r', '')\n",
    "print(database+'/console/?mode=compact#sql/explain/create/'+stmt +profileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Results\n",
    "Now we can create indexes to see if we can improve the overall performance of the workloads. The next cell will create indexes on the SALARY column of the Employees table as well as the DEPTO of both the DEPARTMENTS and EMPLOYEES tables. We can also update statistics to make sure the optimizer has the best results to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createIndexes = \\\n",
    "'''\n",
    "CREATE INDEX ix_salary\n",
    "ON EMPLOYEES(SALARY);\n",
    "\n",
    "CREATE INDEX ix_empdept\n",
    "ON EMPLOYEES(DEPTNO);\n",
    "\n",
    "CREATE INDEX ix_dept\n",
    "ON DEPARTMENTS(DEPTNO);\n",
    "'''\n",
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [createIndexes]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('Creating Indexes for Profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateStats = \\\n",
    "'''\n",
    "call sysproc.admin_cmd('RUNSTATS ON TABLE db2inst1.employees ON KEY COLUMNS and INDEXES ALL');\n",
    "call sysproc.admin_cmd('RUNSTATS ON TABLE db2inst1.departments ON KEY COLUMNS and INDEXES ALL');\n",
    "'''\n",
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [updateStats]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('Updating Statistics for Profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if visual explain predicts any improvements.\n",
    "\n",
    "**3.1.1 Note:** Unfortunately there was a regression in ability to call this function directly through a URL. It is supported in 3.1 and will be addressed in 3.1.2. If you are currently using 3.1.1 please rerun the visual explain analysis through the Db2 Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually explain the access plan for an SQL Statement\n",
    "profileURL = \"?profile=\"+slowestProfile\n",
    "stmt = slowestSQL.replace('\\n', ' ').replace('\\r', '')\n",
    "print(database+'/console/?mode=compact#sql/explain/create/'+stmt +profileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will repeat the original workload performance run to see if there is a measureable difference in performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [sqlScriptWorkload1, sqlScriptWorkload2]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "profileReps = 2\n",
    "scriptReps = 4\n",
    "\n",
    "df = runScripts(profileList, scriptList, user, password, profileReps, scriptReps)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total runtime in ms')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "stmtSum = df.groupby(['statement']).sum()\n",
    "print(stmtSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to your original performance without indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean runtime in ms')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "profileSum = df.groupby(['profile']).sum()\n",
    "profileSum.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "\n",
    "If you want to run the lab again, or try with different indexes, you can use the cells below to drop either the current indexes or the original tables. \n",
    "\n",
    "Experiment with different SQL Statements, and different tables to see what your results look like. You can even try to create new cells that will run different workloads on different databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropIndexes = \\\n",
    "'''\n",
    "DROP INDEX ix_salary;\n",
    "DROP INDEX ix_empdept;\n",
    "DROP INDEX ix_dept;\n",
    "'''\n",
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [dropIndexes]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('Profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropTables = \\\n",
    "'''\n",
    "DROP TABLE EMPLOYEES;\n",
    "DROP TABLE DEPARTMENTS;\n",
    "'''\n",
    "profileList = ['SAMPLE','HISTORY']\n",
    "scriptList = [dropTables]\n",
    "user = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "for profile in profileList :\n",
    "    print('Profile: '+profile)\n",
    "    for script in scriptList :\n",
    "        json = runSQL(profile, user, password, script)\n",
    "        displayResults(json)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019-2021, Peter Kohlmann [kohlmann@ca.ibm.com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
